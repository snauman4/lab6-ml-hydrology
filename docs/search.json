[
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(ggplot2)\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "lab6.html#data-splitting",
    "href": "lab6.html#data-splitting",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Data Splitting",
    "text": "Data Splitting\n\n# set a new seed for reproducible\nset.seed(123456) # new sequence\n\n# create initial 75% training and 25% testing split and extract the sets\ncamels_strata &lt;- initial_split(camels, prop = .75)\n\ntrain_camels &lt;- training(camels_strata)\ntest_camels &lt;- testing(camels_strata)\n\n# build a 10-fold CV dataset\ncamels_folds &lt;-\n  vfold_cv(train_camels, v = 10)"
  },
  {
    "objectID": "lab6.html#recipe",
    "href": "lab6.html#recipe",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Recipe",
    "text": "Recipe\n\n# define a formula you want to use\nformula &lt;- logQmean ~ p_mean + aridity + high_prec_dur\n\n# build a recipe\ntrain_camels &lt;- na.omit(train_camels)\nrec_camels &lt;-  recipe(logQmean ~ p_mean + aridity + high_prec_dur, data = train_camels) %&gt;%\n  step_log(all_predictors()) %&gt;%\n  step_interact(terms = ~ aridity:p_mean) %&gt;%\n  step_naomit(all_predictors(), all_outcomes()) %&gt;%\n  step_zv(all_predictors()) \n\n# prep the data\nbaked_camels &lt;- prep(rec_camels, train_camels) %&gt;%\n  bake(new_data = NULL)\n\n# check the recipe (should be zero)\nsum(is.na(baked_camels))\n\n[1] 0\n\nsum(is.infinite(as.matrix(baked_camels))) \n\n[1] 0\n\n\n\nThe formula was chose was based on the inclusion of the predictor variables that I believe influence mean daily discharge: p_mean, aridity, and logQmean. Precipitation adds water to the system, while aridity indicates how dry an area is (drier areas usually have lower logQmean). I also expect that more frequent heavy rain events (high_prec_dur) will lead to higher average discharge."
  },
  {
    "objectID": "lab6.html#define-3-models",
    "href": "lab6.html#define-3-models",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Define 3 Models",
    "text": "Define 3 Models\n\n# define a random forest model\nq4_rf_mod &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n# 2 other models of choice\nq4_xgb_mod &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\") \n\nq4_lm_mod &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")"
  },
  {
    "objectID": "lab6.html#workflow-set",
    "href": "lab6.html#workflow-set",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Workflow Set",
    "text": "Workflow Set\n\n# create workflow objects, add the recipe, add the models\nq4_rf_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_camels) %&gt;%\n  add_model(q4_rf_mod)\n\nq4_xgb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_camels) %&gt;%\n  add_model(q4_xgb_mod)\n\nq4_lm_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_camels) %&gt;%\n  add_model(q4_lm_mod) \n\n# fit the model to the resamples\nrf_results &lt;- fit_resamples(q4_rf_wf, resamples = camels_folds)\nxgb_results &lt;- fit_resamples(q4_xgb_wf, resamples = camels_folds) \nlm_results &lt;- fit_resamples(q4_lm_wf, resamples = camels_folds)"
  },
  {
    "objectID": "lab6.html#evaluation",
    "href": "lab6.html#evaluation",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Evaluation",
    "text": "Evaluation\n\n# use autoplot and rank_results to compare the models\nq4_wf &lt;- workflow_set(list(rec_camels), list(q4_rf_mod, q4_xgb_mod, q4_lm_mod)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv)\n\nautoplot(q4_wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 4 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_linear_reg Prepro… rmse    0.569  0.0260    10 recipe       line…     1\n2 recipe_linear_reg Prepro… rsq     0.770  0.0223    10 recipe       line…     1\n3 recipe_rand_fore… Prepro… rmse    0.565  0.0249    10 recipe       rand…     2\n4 recipe_rand_fore… Prepro… rsq     0.769  0.0261    10 recipe       rand…     2\n\n\n\nOut of the random forest, linear, and xgboost model, I think that the random forest model is the strongest performer because it shows the lowest RMSE and the highest RSQ compared to the others, capturing the relationship between predictors and response very well. These metrics indicate that the random forest’s predictions are close to the actual values and explain a large variance in the data. This means it consistently makes accurate predictions and captures the underlying patterns in the dataset better than the other models."
  },
  {
    "objectID": "lab6.html#extract-and-evaluate",
    "href": "lab6.html#extract-and-evaluate",
    "title": "Lab 6: Machine Learning in Hydrology",
    "section": "Extract and Evaluate",
    "text": "Extract and Evaluate\n\n# build a workflow with favorite model, recipe, and training data\nfinal_wf &lt;- workflow() %&gt;%\n  add_recipe(rec_camels) %&gt;%\n  add_model(q4_rf_mod) %&gt;%\n  fit(data = train_camels) # use fit to fit all training data to the model\n\n# use augment to make preditions on the test data\nfinal_wf_data &lt;- augment(final_wf, new_data = test_camels)\n\n#create a plot of the observed vs predicted values\nggplot(final_wf_data, aes(x = .pred, y = logQmean, colour = logQmean)) +\n  scale_color_gradient2(low = \"blue3\", mid = \"yellow\", high = \"chartreuse\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  labs(title = \"Random Forest Model: Observed vs. Predicted\",\n       x = \"Predicted Log Mean Flow\",\n       y = \"Observed Log Mean Flow?\")\n\n\n\n\n\n\n\n\nThese results suggest that the random forest model performs well on predicting logQmean based on the predictors chosen. Most of the points are along the 1:1 line, indicating that the model’s predicted values match the observed values closely, accurately capturing the relationship between the predictors and logQmean effectively."
  }
]